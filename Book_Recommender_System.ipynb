{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "1ee8e4c9-a972-4849-838d-240da13145e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time # Added time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy import sparse\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "01df9c65-0c40-4f4b-af5d-eed5d507e25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_raw_data(_num_samples, _fn):\n",
    "    _df = pd.read_csv(\"goodreads_interactions.csv\", nrows=_num_samples)\n",
    "    _df = _df[_df.is_read == 1]\n",
    "    _df = _df[0:_num_samples]\n",
    "    _df.to_csv(f'goodreads_{_fn}.csv', index=False)\n",
    "\n",
    "def build_rating_matrix(_df):\n",
    "    _n_users = len(_df.user_id.unique()) + 1\n",
    "    _n_books = _df.book_idx.max() + 1\n",
    "    print(f'Users: {_n_users}')\n",
    "    print(f'Books: {_n_books}')\n",
    "    _ratings = np.zeros((_n_users, _n_books))\n",
    "    for _, row in tqdm(_df.iterrows(), total=len(_df)):\n",
    "        i = row.user_id\n",
    "        j = row.book_idx\n",
    "        _ratings[i, j] = row.rating\n",
    "    return _ratings\n",
    "\n",
    "def recommend_item_similarity(_matrix, _eps, _n_latent):\n",
    "    _item_svd = TruncatedSVD(n_components=_n_latent)\n",
    "    _item_features = _item_svd.fit_transform(_matrix.transpose())\n",
    "    print('Converting to sparse')\n",
    "    _sparse_features = sparse.csr_matrix(_item_features)\n",
    "    return _sparse_features\n",
    "\n",
    "def generate_similarity_matrix(_features, _metric):\n",
    "    assert _metric in ['cityblock', 'cosine', 'euclidean', 'l1', 'l2', 'manhattan']\n",
    "    print('Computing similarity')\n",
    "    _similarity_matrix = pairwise_distances(_features, metric=_metric)\n",
    "    return _similarity_matrix\n",
    "\n",
    "def merge_meta(_meta_path, _map_path, _ratings):\n",
    "    _meta = pd.read_csv(_meta_path)\n",
    "    _map = pd.read_csv(_map_path)\n",
    "    _ratings_map = _ratings.merge(_map, how='left', left_on='book_id', right_on='book_id_csv')\n",
    "    _ratings_map = _ratings_map[['user_id', 'book_id_csv', 'is_read', 'rating', 'is_reviewed', 'book_id_y']]\n",
    "    _ratings_map.columns = ['user_id', 'book_idx', 'is_read', 'rating', 'is_reviewed', 'book_id']\n",
    "    _metadata_lookup = {}\n",
    "    for _, row in _ratings_map.iterrows():\n",
    "        _md = _meta[_meta['book_id'] == row['book_id']]\n",
    "        if not _md.empty:\n",
    "            _metadata_lookup[str(row.book_idx)] = {\n",
    "                'title': _md['title'].values[0],\n",
    "                'link': _md['link'].values[0]\n",
    "            }\n",
    "    return _ratings_map, _metadata_lookup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "5a7a9111-969d-4607-882a-868fc406016c",
   "metadata": {},
   "outputs": [],
   "source": [
    "NS = 8000\n",
    "FN = '8k'\n",
    "EPS = 1e-9\n",
    "FACTORS = 5  # Controls how much compression for the user book matrix\n",
    "METRIC = 'euclidean'  # Similarity Distance Funtion, (SVD)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "e0474583-9a6d-4d39-9b6a-ff6dafbc4f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    goodreads = pd.read_csv(f'goodreads_{FN}.csv')\n",
    "except FileNotFoundError:\n",
    "    read_raw_data(NS, FN)\n",
    "    goodreads = pd.read_csv(f'goodreads_{FN}.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "b38e6ff9-44f3-46b0-9060-5249d3932b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_meta, metadata_lookup = merge_meta(\n",
    "    'book_metadata.csv',\n",
    "    'book_id_map.csv',\n",
    "    goodreads\n",
    ")\n",
    "\n",
    "with open(f'books_metadata_{FN}.json', 'w', encoding='utf-8') as m:\n",
    "    json.dump(metadata_lookup, m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "eaeadab4-28af-44d4-af05-4a3a6e3a3caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users: 11\n",
      "Books: 7519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2024/2024 [00:00<00:00, 64077.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting to sparse\n",
      "Computing similarity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity computation time: 0.40 seconds\n"
     ]
    }
   ],
   "source": [
    "ratings = build_rating_matrix(ratings_meta)\n",
    "item_features = recommend_item_similarity(ratings, EPS, FACTORS)\n",
    "\n",
    "start_time = time.time() # Start time\n",
    "sim = generate_similarity_matrix(item_features, METRIC)\n",
    "end_time = time.time() # End Time\n",
    "\n",
    "print(f\"Similarity computation time: {end_time - start_time:.2f} seconds\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "a5b7e338-c6b0-462b-87a1-c261238b672c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity matrix saved.\n"
     ]
    }
   ],
   "source": [
    "with open(f'book_similarity_{FACTORS}_{FN}_{METRIC}.pkl', 'wb') as f:\n",
    "    pickle.dump(sim, f)\n",
    "print(\"Similarity matrix saved.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "a9943e77-dc6e-427b-8c71-14263ebaa35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "\n",
    "def test_recommender(_search, _similarity, _metadata):\n",
    "    \"\"\"\n",
    "    A function to test our recommender system.\n",
    "    :param _search: A book ID to search for.\n",
    "    :param _similarity: Our recommender similarity matrix.\n",
    "    :param _metadata: Mapping of book ID to title.\n",
    "    :return: List of titles of top 5 most similar books.\n",
    "    \"\"\"\n",
    "    row_sims = _similarity[_search, ]\n",
    "    res = sorted(range(len(row_sims)), key=lambda sub: row_sims[sub])[-5:]\n",
    "    print('Searched for book:', _metadata[str(_search)]['title'])\n",
    "    for j, _ in enumerate(res):\n",
    "        print(f'Match {j + 1}: {_metadata[str(res[j])][\"title\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "01b04a99-a7bb-486a-8a67-f88f87ed620d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity matrix loaded.\n",
      "Metadata loaded.\n"
     ]
    }
   ],
   "source": [
    "# Match the build paramters if changed\n",
    "FN = '8k'\n",
    "FACTORS = 5  # Compression\n",
    "METRIC = 'euclidean'  # SVD\n",
    "\n",
    "SIM_PATH = f'book_similarity_{FACTORS}_{FN}_{METRIC}.pkl'\n",
    "META_PATH = f'books_metadata_{FN}.json'\n",
    "\n",
    "# Load similarity matrix\n",
    "with open(SIM_PATH, 'rb') as f:\n",
    "    sim = pickle.load(f)\n",
    "print(\"Similarity matrix loaded.\")\n",
    "\n",
    "# Load metadata\n",
    "with open(META_PATH, 'r', encoding='utf-8') as m:\n",
    "    metadata_lookup = json.load(m)\n",
    "print(\"Metadata loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "ed73f96b-00d9-4a06-923c-61d459772d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searched for book: The Ultimate Hitchhiker's Guide: Five Complete Novels and One Story (Hitchhiker's Guide to the Galaxy, #1-5)\n",
      "Match 1: Memoirs of a Geisha\n",
      "Match 2: Catching Fire (The Hunger Games, #2)\n",
      "Match 3: The Scorch Trials (Maze Runner, #2)\n",
      "Match 4: Pride and Prejudice\n",
      "Match 5: Insurgent (Divergent, #2)\n"
     ]
    }
   ],
   "source": [
    "# Book ID 948 \n",
    "test_recommender(948, sim, metadata_lookup)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "3346ea6f-2cf3-4a10-aec0-3c1cbee72817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users: 7\n",
      "Books: 7076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1329/1329 [00:00<00:00, 72838.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting to sparse\n",
      "Computing similarity...\n",
      "User similarity computation time: 0.00 seconds\n",
      "User similarity matrix saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy import sparse\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def merge_meta(_meta_path, _map_path, _ratings):\n",
    "    \"\"\"\n",
    "    Merges book metadata with ratings.\n",
    "    Returns ratings with book_idx (needed for building matrix).\n",
    "    \"\"\"\n",
    "    _meta = pd.read_csv(_meta_path)\n",
    "    _map = pd.read_csv(_map_path)\n",
    "    _ratings_map = _ratings.merge(_map, how='left',\n",
    "                                  left_on='book_id', right_on='book_id_csv')\n",
    "    _ratings_map = _ratings_map[['user_id', 'book_id_csv', 'is_read',\n",
    "                                 'rating', 'is_reviewed', 'book_id_y']]\n",
    "    _ratings_map.columns = ['user_id', 'book_idx', 'is_read',\n",
    "                            'rating', 'is_reviewed', 'book_id']\n",
    "    return _ratings_map\n",
    "\n",
    "\n",
    "def build_rating_matrix(_df):\n",
    "    _n_users = len(_df.user_id.unique()) + 1\n",
    "    _n_books = _df.book_idx.max() + 1\n",
    "    print(f'Users: {_n_users}')\n",
    "    print(f'Books: {_n_books}')\n",
    "    _ratings = np.zeros((_n_users, _n_books))\n",
    "    for _, row in tqdm(_df.iterrows(), total=len(_df)):\n",
    "        i = row.user_id\n",
    "        j = row.book_idx\n",
    "        _ratings[i, j] = row.rating\n",
    "    return _ratings\n",
    "\n",
    "\n",
    "def recommend_user_similarity(_matrix, _eps, _n_latent):\n",
    "    svd = TruncatedSVD(n_components=_n_latent)\n",
    "    user_features = svd.fit_transform(_matrix)\n",
    "    print('Converting to sparse')\n",
    "    return sparse.csr_matrix(user_features)\n",
    "\n",
    "\n",
    "def generate_similarity_matrix(_features, _metric):\n",
    "    print('Computing similarity...')\n",
    "    _similarity_matrix = pairwise_distances(_features, metric=_metric)\n",
    "    return _similarity_matrix\n",
    "\n",
    "\n",
    "# --- Main execution ---\n",
    "\n",
    "NS = 5000           # Sample size\n",
    "FN = '5k'           # File name suffix\n",
    "EPS = 1e-9          # Epsilon for numerical stability (not used here directly)\n",
    "FACTORS = 2         # Latent factors for SVD\n",
    "METRIC = 'cityblock'   # Similarity metric\n",
    "\n",
    "# Load raw ratings file\n",
    "ratings_df_raw = pd.read_csv(f'goodreads_{FN}.csv')\n",
    "\n",
    "# Merge metadata to get book_idx\n",
    "ratings_df = merge_meta('book_metadata.csv', 'book_id_map.csv', ratings_df_raw)\n",
    "\n",
    "# Build user-item matrix\n",
    "ratings_matrix = build_rating_matrix(ratings_df)\n",
    "\n",
    "# Generate user similarity features\n",
    "user_features = recommend_user_similarity(ratings_matrix, EPS, FACTORS)\n",
    "\n",
    "# Compute user-user similarity matrix\n",
    "start = time.time()\n",
    "user_sim = generate_similarity_matrix(user_features, METRIC)\n",
    "end = time.time()\n",
    "print(f'User similarity computation time: {end - start:.2f} seconds')\n",
    "\n",
    "# Save similarity matrix to file\n",
    "with open(f'user_similarity_{FACTORS}_{FN}_{METRIC}.pkl', 'wb') as f:\n",
    "    pickle.dump(user_sim, f)\n",
    "\n",
    "print(\"User similarity matrix saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "126879ff-9cd4-4405-b63d-143143854494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 7)\n"
     ]
    }
   ],
   "source": [
    "# Check to see what the user ID range is\n",
    "\n",
    "print(user_sim.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "6f0ed74d-dcfd-4257-b999-6856f48e4e54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Most similar users to User 3:\n",
      "\n",
      "User 6 (Similarity score: 0.6801)\n",
      "\n",
      "User 4 (Similarity score: 2.9406)\n",
      "  - 5.0: The Fault in Our Stars\n",
      "  - 5.0: Wonder\n",
      "  - 5.0: Valley of the Dolls\n",
      "\n",
      "User 1 (Similarity score: 5.0589)\n",
      "  - 5.0: Ramona Forever (Ramona, #7)\n",
      "  - 5.0: The Fellowship of the Ring (The Lord of the Rings, #1)\n",
      "  - 5.0: A Bear Called Paddington (Paddington, #1)\n",
      "\n",
      "User 2 (Similarity score: 5.5108)\n",
      "  - 5.0: Peace Like a River\n",
      "  - 5.0: Little Bee\n",
      "  - 5.0: The Poisonwood Bible\n",
      "\n",
      "User 5 (Similarity score: 68.8338)\n",
      "  - 5.0: The Hunger Games (The Hunger Games, #1)\n",
      "  - 5.0: Divergent (Divergent, #1)\n",
      "  - 5.0: Resolved to Rule (Blood and Snow, #11)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def test_user_recommender(_user_id, _similarity, _ratings_df, _metadata, _top_n=5):\n",
    "    \"\"\"\n",
    "    Prints the top N most similar users to the given user_id and their top-rated books.\n",
    "\n",
    "    :param _user_id: The user ID to search for.\n",
    "    :param _similarity: The user-user similarity matrix.\n",
    "    :param _ratings_df: DataFrame with user-book ratings (must include book_idx and rating).\n",
    "    :param _metadata: Dict with book_idx -> {title, link}.\n",
    "    :param _top_n: Number of similar users to return.\n",
    "    \"\"\"\n",
    "    user_similarities = _similarity[_user_id]\n",
    "    similar_users = sorted(\n",
    "        [(i, sim) for i, sim in enumerate(user_similarities) if i != _user_id],\n",
    "        key=lambda x: x[1]\n",
    "    )[:_top_n]  # Closest users (lowest distance for cosine)\n",
    "\n",
    "    print(f\"\\nMost similar users to User {_user_id}:\\n\")\n",
    "    for rank, (uid, sim) in enumerate(similar_users, start=1):\n",
    "        print(f\"User {uid} (Similarity score: {sim:.4f})\")\n",
    "\n",
    "        user_books = _ratings_df[_ratings_df.user_id == uid]\n",
    "        top_books = user_books.sort_values(by='rating', ascending=False).head(3)\n",
    "\n",
    "        for _, row in top_books.iterrows():\n",
    "            book_idx = str(int(row.book_idx))  # Ensure string keys match metadata keys\n",
    "            if book_idx in _metadata:\n",
    "                print(f\"  - {row.rating:.1f}: {_metadata[book_idx]['title']}\")\n",
    "        print(\"\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Match these to the build script\n",
    "    FN = '5k'\n",
    "    FACTORS = 2\n",
    "    METRIC = 'cityblock'\n",
    "\n",
    "    # Load similarity matrix\n",
    "    with open(f'user_similarity_{FACTORS}_{FN}_{METRIC}.pkl', 'rb') as f:\n",
    "        user_sim = pickle.load(f)\n",
    "\n",
    "    # Load metadata\n",
    "    with open(f'books_metadata_{FN}.json', 'r', encoding='utf-8') as f:\n",
    "        metadata = json.load(f)\n",
    "\n",
    "    # Load and merge ratings\n",
    "    ratings_raw = pd.read_csv(f'goodreads_{FN}.csv')\n",
    "\n",
    "    def merge_meta(_meta_path, _map_path, _ratings):\n",
    "        _meta = pd.read_csv(_meta_path)\n",
    "        _map = pd.read_csv(_map_path)\n",
    "        _ratings_map = _ratings.merge(_map, how='left',\n",
    "                                      left_on='book_id', right_on='book_id_csv')\n",
    "        _ratings_map = _ratings_map[['user_id', 'book_id_csv', 'is_read',\n",
    "                                     'rating', 'is_reviewed', 'book_id_y']]\n",
    "        _ratings_map.columns = ['user_id', 'book_idx', 'is_read',\n",
    "                                'rating', 'is_reviewed', 'book_id']\n",
    "        return _ratings_map\n",
    "\n",
    "    ratings_df = merge_meta('book_metadata.csv', 'book_id_map.csv', ratings_raw)\n",
    "\n",
    "    # Test user similarity for a given user\n",
    "    test_user_id = 3  # You can try different values from the ID check\n",
    "    test_user_recommender(test_user_id, user_sim, ratings_df, metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "a289c551-dc39-4f42-8e20-4a543b7df420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Roy_Phelps_HW2_Code.zip created with 1 files.\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "\n",
    "# Define the name of your zip file\n",
    "zip_name = 'Roy_Phelps_HW2_Code.zip'\n",
    "\n",
    "# List of files to include (update these as needed)\n",
    "files_to_zip = [\n",
    "    'Roy_Phelps_HW2_Code.ipynb'\n",
    "]\n",
    "\n",
    "# Create the zip file\n",
    "with zipfile.ZipFile(zip_name, 'w') as z:\n",
    "    for file in files_to_zip:\n",
    "        z.write(file)\n",
    "\n",
    "print(f\"{zip_name} created with {len(files_to_zip)} files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18cc6a36-f7cb-47e5-8ed7-e9a9b09241ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
